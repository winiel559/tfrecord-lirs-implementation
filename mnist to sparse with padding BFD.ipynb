{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#https://medium.com/%E8%BB%9F%E9%AB%94%E4%B9%8B%E5%BF%83/%E9%81%A9%E5%90%88%E5%A4%A7%E9%87%8F%E8%B3%87%E6%96%99i-o%E7%9A%84%E5%84%B2%E5%AD%98%E6%A0%BC%E5%BC%8F-tfrecord%E7%B0%A1%E4%BB%8B%E8%88%87%E6%93%8D%E4%BD%9C%E6%95%99%E5%AD%B8-cd27e50d51ee\n",
    "\n",
    "# mnist one example consists of 28*28 byte + 1 byte\n",
    "# if _bytes_feature's args is alreaddy a list, no need to use []\n",
    "def _image_feature(value):\n",
    "    \"\"\"\"Returns a uint8(byte)_list from a byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        # BytesList won't unpack a string from an EagerTensor.\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _label_feature(value):\n",
    "    \"\"\"Returns a uint8(byte)_list from a byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4000 8000 12000 16000 20000 24000 28000 32000 36000 40000 44000 48000 52000 56000 "
     ]
    }
   ],
   "source": [
    "\"\"\" transfer dataset to tfrecord method\"\"\"\n",
    "# the whole image is a byte feature, not a byte list\n",
    "import os\n",
    "import struct                                                                   \n",
    "import numpy as np                                                              \n",
    "import matplotlib.pyplot as plt                                                 \n",
    "from PIL import Image\n",
    "from queue import PriorityQueue as PQ\n",
    "def serialize_example(_label, _image):\n",
    "    feature = {\n",
    "        \"label\": _label_feature(_label),\n",
    "        \"image\": _image_feature(_image),\n",
    "        }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString() \n",
    "\n",
    "images_file_name = './train-images.idx3-ubyte'\n",
    "labels_file_name = './train-labels.idx1-ubyte'\n",
    "images_dir = './mnist jpeg/'\n",
    "oft_file_name='mnist-sparse_padded_BFD-offset_table'\n",
    "tfr_file_name='mnist_sparse_padded_BFD.tfrecords'\n",
    "mnist_images=open(images_file_name,'rb')\n",
    "mnist_labels=open(labels_file_name,'rb')\n",
    "# skip header file\n",
    "_=mnist_images.read(16)\n",
    "_=mnist_labels.read(8)\n",
    "\n",
    "# data\n",
    "# build offset_table while writing TFRecords, int64 for offset of each instance, e.g. offset of instance #100 is 100*8B=800B\n",
    "# byte is little endian\n",
    "offset_table=open(oft_file_name,'wb') \n",
    "\n",
    "\"\"\"\n",
    "class Bin(object):\n",
    "    # Container for items that keeps a running sum \n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "        self.sum = 0\n",
    "\n",
    "    def append(self, item):\n",
    "        self.items.append(item)\n",
    "        self.sum += item.w\n",
    "\n",
    "    def __str__(self):\n",
    "        # Printable representation \n",
    "        return 'Bin(sum=%d, items=%s)' % (self.sum, str(self.items))\n",
    "\n",
    "class Instance(object):\n",
    "    def __init__(self):\n",
    "        # idx: original idx in the file\n",
    "        self.idx=-1\n",
    "        self.w=0\n",
    "\"\"\"\n",
    "\n",
    "# BFD algorithm, input: all instances; output: BFD order (e.g. [0,2,1] means in rewrited dataset the order is ins #0 #2 #1)\n",
    "# items contains [w,idx] of each item, remain_w in front for sorting\n",
    "# bins contains idx of instances inside it (e.g. [[0,1,3],[2,4,5]] means bin1 has ins #0 #1 #3)\n",
    "# bins_remain_w contains [remain_w,bin_idx] of each bin, remain_w in front for sorting\n",
    "\n",
    "# bins contains [remain_w,[item_idx]]\n",
    "items=[]\n",
    "\n",
    "#bins_remain_w=[]\n",
    "\n",
    "# pre BFD\n",
    "# know the length of each instance\n",
    "for i in range (60000):\n",
    "    len_record=0\n",
    "    if(i%4000==0):\n",
    "        print(i,end=' ')\n",
    "    with open(images_dir+str(i)+'.jpg','rb') as f:\n",
    "        buf=mnist_labels.read(1)\n",
    "        _label=buf\n",
    "        img_bytes=f.read()\n",
    "        serialized_example = serialize_example(_label, img_bytes)\n",
    "        # 16B metadata\n",
    "        len_record=len(serialized_example)+16        \n",
    "    item=[len_record,i]\n",
    "    items.append(item)\n",
    "\n",
    "# BFD step 1: sort all items, heaviest first\n",
    "items.sort()\n",
    "items.reverse()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 0.07555270195007324\n",
      "4000 0.1880054473876953\n",
      "6000 0.325986385345459\n",
      "8000 0.4867067337036133\n",
      "10000 0.525585412979126\n",
      "12000 0.6290006637573242\n",
      "14000 0.741999626159668\n",
      "16000 0.8637411594390869\n",
      "18000 1.0690157413482666\n",
      "20000 1.099003791809082\n",
      "22000 1.318619728088379\n",
      "24000 1.3610000610351562\n",
      "26000 1.527590274810791\n",
      "28000 1.7871003150939941\n",
      "30000 2.113316297531128\n",
      "32000 2.1798694133758545\n",
      "34000 2.221944808959961\n",
      "36000 2.4971282482147217\n",
      "38000 2.558633804321289\n",
      "40000 2.803603410720825\n",
      "42000 3.080460786819458\n",
      "44000 3.237412452697754\n",
      "46000 3.478344202041626\n",
      "48000 3.7300477027893066\n",
      "50000 3.8299238681793213\n",
      "52000 3.9636003971099854\n",
      "54000 4.151292324066162\n",
      "56000 4.345522403717041\n",
      "58000 4.515048265457153\n",
      "60000 4.75064754486084\n",
      "2\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# BFD step 2: For each item, find a bin with the maximum load into which the item can fit, if any.\n",
    "#TODO: O(N^2) implementation, use binary search to achieve O(NlogN), 手刻可能比較快\n",
    "# initialize first bin\n",
    "bins=[]\n",
    "A=[4096,[]]\n",
    "bins.append(A)\n",
    "c=0\n",
    "start_t=time.time()\n",
    "for item in items:\n",
    "    \n",
    "    #print(\"processing item \",item[1])\n",
    "    \n",
    "    c+=1\n",
    "    if(c%2000==0):\n",
    "        end_t=time.time()\n",
    "        print(c,end_t-start_t)\n",
    "        start_t=time.time()\n",
    "    no_bin=True\n",
    "    for B in bins:\n",
    "        # if B has enough space, put item into B, break\n",
    "        if B[0]>=item[0]:\n",
    "            B[0]-=item[0]\n",
    "            B[1].append(item[1])\n",
    "            no_bin=False\n",
    "            break\n",
    "    # if no bins is big enough for item, open a new one\n",
    "    if no_bin:\n",
    "        A=[4096-item[0],[item[1]]]        \n",
    "        bins.append(A)\n",
    "    bins.sort()\n",
    "c=0\n",
    "for B in bins:\n",
    "    #print(len(B[1]))\n",
    "    c+=len(B[1])\n",
    "print(c)\n",
    "#print(bins[:10])\n",
    "#print(bins[-10:])\n",
    "# If such a bin is found, the new item is placed inside it.\n",
    "# Otherwise, a new bin is opened and the coming item is placed inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 offset= 0\n",
      "4000 offset= 2672383\n",
      "8000 offset= 5374539\n",
      "12000 offset= 8053940\n",
      "16000 offset= 10661888\n",
      "20000 offset= 13181595\n",
      "24000 offset= 15756600\n",
      "28000 offset= 18397086\n",
      "32000 offset= 21055369\n",
      "36000 offset= 23717478\n",
      "40000 offset= 26399802\n",
      "44000 offset= 29080008\n",
      "48000 offset= 31757528\n",
      "52000 offset= 34438147\n",
      "56000 offset= 37120997\n"
     ]
    }
   ],
   "source": [
    "# write as BFD order\n",
    "# for each bin, write each instance of bin[1]\n",
    "with tf.io.TFRecordWriter(tfr_file_name) as writer:\n",
    "    # page size=4KB, padding to write to another page if the next instance exceeds the page\n",
    "    \n",
    "    \"\"\"padding needs to ne slightly modified: because padded record needs at least 16B, \n",
    "    instead of see if after_ptr exceeds, see if after_ptr+16 exceeds \"\"\"\n",
    "    \n",
    "    cur_page=0\n",
    "    c=0\n",
    "    for B in bins:\n",
    "        for i in B[1]:\n",
    "            # current tfr file ptr = current_filesize\n",
    "            with open(images_dir+str(i)+'.jpg','rb') as f:\n",
    "                buf=mnist_labels.read(1)\n",
    "                _label=buf\n",
    "                img_bytes=f.read()            \n",
    "\n",
    "                current_filesize=os.path.getsize(tfr_file_name)\n",
    "                # test if exceeds or not, other 3 columns: 16B\n",
    "                cur_page=int(current_filesize/4096)\n",
    "                serialized_example = serialize_example(_label, img_bytes)\n",
    "                calc_new_filesize=current_filesize+len(serialized_example)+16+16\n",
    "                calc_new_page=int(calc_new_filesize/4096)            \n",
    "\n",
    "                if(calc_new_page>cur_page):\n",
    "                    # if exceeds: padding until reaching new page\n",
    "                    #TODO: the pad still needs 16B metadata\n",
    "                    pad_len=calc_new_page*4096-current_filesize\n",
    "                    #print(\"before pad:\",current_filesize)\n",
    "                    pad=b''\n",
    "                    if(pad_len-16>0):                    \n",
    "                        for _ in range (pad_len-16):\n",
    "                            pad+=b'0'\n",
    "                        #print(\"len(pad)=\",len(pad))\n",
    "                        writer.write(pad)\n",
    "                        #current_filesize=os.path.getsize(\"mnist_sparse_padded.tfrecords\") \n",
    "                        #print(\"after pad\",current_filesize)\n",
    "                    else:\n",
    "                        print(\"error\")\n",
    "                current_filesize=os.path.getsize(tfr_file_name) \n",
    "                #print(\"after after pad\",current_filesize)\n",
    "                if(c%4000==0):\n",
    "                    print(c,end=' ')\n",
    "                    print(\"offset=\",current_filesize)\n",
    "                c+=1\n",
    "                \"\"\"\n",
    "                if(i<10):\n",
    "                    print(current_filesize,calc_new_filesize,end=' ')\n",
    "                    print(cur_page,calc_new_page, end=' ')\n",
    "                    print(len(serialized_example))\n",
    "                else:\n",
    "                    break\n",
    "                \"\"\"    \n",
    "                offset_table.write(current_filesize.to_bytes(8, byteorder = 'little')) \n",
    "                writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" standard way to iterate tfr, to make sure the tfr format is right \"\"\"\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(tfr_file_name)\n",
    "\n",
    "image_feature_description = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    # var len is different\n",
    "    'image': tf.io.FixedLenFeature([],tf.string),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    serialized_example = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    return serialized_example\n",
    "\n",
    "\n",
    "for idx, features in enumerate(dataset):\n",
    "    parsed_features = _parse_function(features)\n",
    "    print(\"label=\",parsed_features['label'].numpy())    \n",
    "    image=tf.io.decode_jpeg(parsed_features['image'])\n",
    "    plt.imshow(np.asarray(image).reshape((28,28)),cmap = plt.cm.gray)                                        \n",
    "    plt.show()\n",
    "    \n",
    "    if idx>=11:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2720357\n",
      "5440147\n",
      "8161859\n",
      "10880771\n",
      "13597054\n",
      "16320380\n",
      "19037277\n",
      "21751540\n",
      "24468494\n",
      "27184230\n",
      "29902677\n",
      "32623537\n",
      "35341560\n",
      "38058426\n"
     ]
    }
   ],
   "source": [
    "\"\"\"offset table read test\"\"\"\n",
    "\n",
    "oft=open(oft_file_name,'rb')\n",
    "idx=5\n",
    "for i in range (60000):\n",
    "    \n",
    "    tmp=oft.read(8)\n",
    "    #print(tmp)\n",
    "    if(i%4000==0):\n",
    "        length=struct.unpack(\"<Q\",tmp)\n",
    "        print(length[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" the actual read() function \"\"\"\n",
    "\n",
    "def sparse_random_read(binfile, oft, idx):\n",
    "    # read offset, 8B per instance\n",
    "    #TODO: oft should be loaded to mem\n",
    "    oft.seek(idx*8,0)\n",
    "    tmp=oft.read(8)\n",
    "    offset=struct.unpack(\"<Q\",tmp)[0]\n",
    "    print(\"offset=\",offset)\n",
    "    \n",
    "    # read data length\n",
    "    binfile.seek(offset,0)\n",
    "    tmp=binfile.read(8)\n",
    "    length=struct.unpack(\"<Q\",tmp)[0]\n",
    "    print(\"length=\",length)\n",
    "    # we already read first 8B\n",
    "    record_l_from_col2=length+8\n",
    "    \n",
    "    # random read\n",
    "    tmp=binfile.read(record_l_from_col2)\n",
    "    r_data=tmp[4:-4]\n",
    "\n",
    "    # deserialize data\n",
    "    parsed_features = _parse_function(r_data)\n",
    "    return parsed_features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset= 4389853\n",
      "length= 604\n",
      "tf.Tensor(b'\\x07', shape=(), dtype=string)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" test read() function \"\"\"\n",
    "\n",
    "binfile=open(tfr_file_name,'rb')\n",
    "oftfile=open(oft_file_name,'rb')\n",
    "parsed_feature=sparse_random_read(binfile,oftfile, 6455)\n",
    "image=tf.io.decode_jpeg(parsed_feature['image'])\n",
    "print(parsed_feature['label'])\n",
    "np_image=np.frombuffer(image, dtype='>B').astype(np.uint8)\n",
    "plt.imshow(np.asarray(np_image).reshape((28,28)),cmap = plt.cm.gray)                                        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
